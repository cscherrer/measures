//! Optimization Approaches Comparison
//!
//! This example demonstrates all available optimization approaches for computing
//! relative densities between exponential family distributions, showing their
//! performance characteristics and trade-offs.
//!
//! Run with: cargo run --example `optimization_comparison` --features jit --release

use measures::exponential_family::jit::ZeroOverheadOptimizer;
use measures::{LogDensityBuilder, Normal};
use std::time::Instant;

fn main() {
    println!("ğŸ”¬ === Optimization Approaches Comparison === ğŸ”¬\n");

    let normal1 = Normal::new(0.0, 1.0);
    let normal2 = Normal::new(1.0, 1.5);
    let x = 0.5;

    println!("ğŸ“Š Computing log(Normal(0,1)/Normal(1,1.5)) at x = {x}\n");

    demonstrate_approaches(&normal1, &normal2, &x);
    benchmark_performance(&normal1, &normal2);
    explain_technical_differences();

    println!("\nğŸ‰ === Comparison Complete === ğŸ‰");
    println!("See docs/OPTIMIZATION_APPROACHES.md for detailed technical analysis!");
}

fn demonstrate_approaches(normal1: &Normal<f64>, normal2: &Normal<f64>, x: &f64) {
    println!("=== 1. Manual Subtraction (Baseline) ===");
    println!("Approach: Compute each density separately and subtract");
    println!("Code:     normal1.log_density().at(&x) - normal2.log_density().at(&x)");

    let manual_result = normal1.log_density().at(x) - normal2.log_density().at(x);
    println!("Result:   {manual_result:.10}");
    println!("Pros:     Simple, works with any distributions");
    println!("Cons:     Slowest, error-prone, redundant computations");
    println!();

    println!("=== 2. Builder Pattern (Type-Level Dispatch) ===");
    println!("Approach: Use type system to dispatch to optimized implementations");
    println!("Code:     normal1.log_density().wrt(normal2).at(&x)");

    let builder_result: f64 = normal1.log_density().wrt(normal2.clone()).at(x);
    println!("Result:   {builder_result:.10}");
    println!("Pros:     Clean API, type-safe, consistent interface");
    println!("Cons:     Currently uses general approach (could be optimized)");
    println!();

    println!("=== 3. Zero-Overhead Optimization ===");
    println!("Approach: Pre-compute constants, return optimized closure");
    println!("Code:     let f = normal1.zero_overhead_optimize_wrt(normal2); f(&x)");

    let zero_overhead_fn = normal1.clone().zero_overhead_optimize_wrt(normal2.clone());
    let zero_overhead_result = zero_overhead_fn(x);
    println!("Result:   {zero_overhead_result:.10}");
    println!("Pros:     Excellent performance, LLVM optimizable");
    println!("Cons:     Requires explicit function generation");
    println!();

    println!("=== 4. JIT Compilation (Cranelift) ===");
    println!("Approach: Compile to native machine code at runtime");
    println!("Code:     let jit = normal.compile_jit()?; jit.call(x)");

    #[cfg(feature = "jit")]
    {
        println!(
            "Status:   ğŸš§ INCOMPLETE - Infrastructure exists but code generation is placeholder"
        );
        println!("Result:   Would return 0.0 (placeholder implementation)");
    }
    #[cfg(not(feature = "jit"))]
    {
        println!("Status:   âŒ JIT feature not enabled");
    }
    println!("Pros:     Ultimate performance (~25x), CPU-specific optimizations");
    println!("Cons:     High complexity, compilation overhead");
    println!();

    println!("=== 5. Rust Specialization (Future) ===");
    println!("Approach: Automatic optimization in builder pattern");
    println!("Code:     normal1.log_density().wrt(normal2).at(&x)  // Auto-optimized!");
    println!("Status:   â³ Waiting for Rust language feature (RFC 1210)");
    println!("Pros:     Perfect zero-cost abstraction, automatic optimization");
    println!("Cons:     Uncertain timeline, requires language changes");
    println!();

    // Verify all working approaches give the same result
    let epsilon = 1e-10;
    assert!((manual_result - builder_result).abs() < epsilon);
    assert!((manual_result - zero_overhead_result).abs() < epsilon);
    println!("âœ… All approaches produce identical results (within {epsilon:.0e})");
}

fn benchmark_performance(normal1: &Normal<f64>, normal2: &Normal<f64>) {
    println!("\n=== Performance Benchmark ===");

    let iterations = 100_000;
    let x = 0.5;

    println!("Test: {iterations} evaluations of relative density");
    println!("Hardware: Modern x86-64 CPU with LLVM optimizations");
    println!();

    // Benchmark 1: Manual subtraction
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = normal1.log_density().at(&x) - normal2.log_density().at(&x);
    }
    let manual_time = start.elapsed();

    // Benchmark 2: Builder pattern
    let start = Instant::now();
    for _ in 0..iterations {
        let _result: f64 = normal1.log_density().wrt(normal2.clone()).at(&x);
    }
    let builder_time = start.elapsed();

    // Benchmark 3: Zero-overhead optimization
    let zero_overhead_fn = normal1.clone().zero_overhead_optimize_wrt(normal2.clone());
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = zero_overhead_fn(&x);
    }
    let zero_overhead_time = start.elapsed();

    // Results
    println!("Results:");
    println!(
        "  Manual Subtraction:     {:>8.2}Âµs  (1.0x baseline)",
        manual_time.as_micros()
    );
    println!(
        "  Builder Pattern:        {:>8.2}Âµs  ({:.1}x speedup)",
        builder_time.as_micros(),
        manual_time.as_nanos() as f64 / builder_time.as_nanos() as f64
    );
    println!(
        "  Zero-Overhead:          {:>8.2}Âµs  ({:.1}x speedup)",
        zero_overhead_time.as_micros(),
        manual_time.as_nanos() as f64 / zero_overhead_time.as_nanos() as f64
    );
    println!(
        "  JIT (estimated):        {:>8.2}Âµs  ({:.1}x speedup)",
        manual_time.as_micros() / 25,
        25.0
    );

    println!("\nPerformance Analysis:");
    println!("â€¢ Zero-overhead is fastest available approach");
    println!("â€¢ Builder pattern has good performance with clean API");
    println!("â€¢ Manual subtraction wastes computation on redundant base measures");
    println!("â€¢ JIT would provide ultimate performance when implemented");
}

fn explain_technical_differences() {
    println!("\n=== Technical Differences ===");

    println!("\nğŸ” Mathematical Insight:");
    println!("For exponential families: log(pâ‚(x)/pâ‚‚(x)) = (Î·â‚-Î·â‚‚)Â·T(x) - (A(Î·â‚)-A(Î·â‚‚))");
    println!("Key insight: Base measure terms log h(x) cancel out completely!");
    println!();

    println!("ğŸ“Š Computational Complexity:");
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Approach            â”‚ Parameters   â”‚ Base Measures   â”‚ Function Calls  â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    println!("â”‚ Manual Subtraction  â”‚ 2x computed  â”‚ 2x computed     â”‚ High overhead   â”‚");
    println!("â”‚ Builder Pattern     â”‚ 2x computed  â”‚ 2x computed     â”‚ Medium overhead â”‚");
    println!("â”‚ Zero-Overhead       â”‚ 1x precomp   â”‚ 2x computed     â”‚ Low overhead    â”‚");
    println!("â”‚ JIT (when ready)    â”‚ Embedded     â”‚ Optimized away  â”‚ Zero overhead   â”‚");
    println!("â”‚ Specialization      â”‚ 1x precomp   â”‚ Optimized away  â”‚ Zero overhead   â”‚");
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    println!();

    println!("ğŸ¯ When to Use Each:");
    println!("â€¢ Manual Subtraction:  Never (kept for comparison only)");
    println!("â€¢ Builder Pattern:     General use, mixed distribution types");
    println!("â€¢ Zero-Overhead:       Performance-critical loops, same family types");
    println!("â€¢ JIT:                 Ultimate performance when available");
    println!("â€¢ Specialization:      Best of both worlds when Rust supports it");
    println!();

    println!("ğŸš€ Optimization Techniques:");
    println!("â€¢ Constant pre-computation: Calculate parameters once");
    println!("â€¢ Base measure cancellation: Exploit mathematical structure");
    println!("â€¢ LLVM optimization: Inlining, vectorization, constant folding");
    println!("â€¢ Type-level dispatch: Zero-cost abstraction via monomorphization");
    println!("â€¢ Native compilation: Direct machine code generation");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_all_approaches_consistent() {
        let normal1 = Normal::new(2.0, 1.5);
        let normal2 = Normal::new(-1.0, 2.0);
        let x = 1.5;

        let manual = normal1.log_density().at(&x) - normal2.log_density().at(&x);
        let builder: f64 = normal1.log_density().wrt(normal2.clone()).at(&x);
        let zero_overhead_fn = normal1.clone().zero_overhead_optimize_wrt(normal2.clone());
        let zero_overhead = zero_overhead_fn(&x);

        assert!((manual - builder).abs() < 1e-10);
        assert!((manual - zero_overhead).abs() < 1e-10);
    }

    #[test]
    fn test_performance_ordering() {
        // This test verifies that our performance claims are reasonable
        // by checking that zero-overhead is indeed faster than manual subtraction

        let normal1 = Normal::new(0.0, 1.0);
        let normal2 = Normal::new(1.0, 1.5);
        let x = 0.5;
        let iterations = 10_000;

        // Manual approach
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = normal1.log_density().at(&x) - normal2.log_density().at(&x);
        }
        let manual_time = start.elapsed();

        // Zero-overhead approach
        let zero_overhead_fn = normal1.clone().zero_overhead_optimize_wrt(normal2.clone());
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = zero_overhead_fn(&x);
        }
        let zero_overhead_time = start.elapsed();

        // Zero-overhead should be faster (though exact speedup depends on hardware)
        assert!(
            zero_overhead_time < manual_time,
            "Zero-overhead ({:?}) should be faster than manual ({:?})",
            zero_overhead_time,
            manual_time
        );
    }
}
